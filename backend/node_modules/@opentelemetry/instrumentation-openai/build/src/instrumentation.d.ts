import { InstrumentationBase, InstrumentationNodeModuleDefinition } from '@opentelemetry/instrumentation';
import { OpenAIInstrumentationConfig } from './types';
export declare class OpenAIInstrumentation extends InstrumentationBase<OpenAIInstrumentationConfig> {
    private _genaiClientOperationDuration;
    private _genaiClientTokenUsage;
    constructor(config?: OpenAIInstrumentationConfig);
    setConfig(config?: OpenAIInstrumentationConfig): void;
    protected init(): InstrumentationNodeModuleDefinition[];
    _updateMetricInstruments(): void;
    private _getPatchedChatCompletionsCreate;
    /**
     * Start a span for this chat-completion API call. This also emits log events
     * as appropriate for the request params.
     */
    private _startChatCompletionsSpan;
    /**
     * This wraps an instance of a `openai/streaming.Stream.iterator()`, an
     * async iterator. It should yield the chunks unchanged, and gather telemetry
     * data from those chunks, then end the span.
     */
    private _onChatCompletionsStreamIterator;
    private _onChatCompletionsCreateResult;
    private _createAPIPromiseRejectionHandler;
    private _getPatchedEmbeddingsCreate;
    /**
     * Start a span for this chat-completion API call. This also emits log events
     * as appropriate for the request params.
     */
    private _startEmbeddingsSpan;
    private _onEmbeddingsCreateResult;
}
//# sourceMappingURL=instrumentation.d.ts.map